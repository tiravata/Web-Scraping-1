{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "The dataset is a webscraped from IMDB website using BeautifulSoup. This tutorial is an advanced version of my previous notebook and assumes that the user knows the basics of HTML and BeautifulSoup. For a more basic overview please look at the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests import get #the package which fetches the HTML doc from the url for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say if you want to scrape a list of 1000 movies, we would have to send in 1000 requests to the website. Assuming each request takes 1 second to execute, it would take a 1000 seconds to execute. When we explore the website a bit we find noval ways which will help us to execute our scraping much more faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.imdb.com/search/title?release_date=2017&sort=num_votes,desc&page=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the link\n",
    "\n",
    "Exploring the IMDB site for a while we find that while using advanced search feature we can have look at the best movies in the given time frame by 50 movies per page. This reduces our time 50 times as we can extract 50 movies per request.\n",
    "\n",
    "further let's explore the url to have a better understanding of waht is happeninng on each request. The link has following elements:\n",
    "\n",
    "- *release_date*: this is takes in the value for the year we are interested in. (2017 in our case)\n",
    "- *sort*: this takes in the value by which we want to sort our list. (num_votes,desc in our case, desc suggests descending order)\n",
    "- *page*: this takes the page number we are interested in. (1 in our case)\n",
    "\n",
    "Further when you click on the next tab, we get an additional element in the link:\n",
    "\"http://www.imdb.com/search/title?release_date=2017&sort=num_votes,desc&page=2&ref_=adv_nxt\"\n",
    "\n",
    "- ref: this suggests if we want to go on the next or the previous page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html\n",
      "xmlns:og=\"http://ogp.me/ns#\"\n",
      "xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
      "    <head>\n",
      "        <meta charset=\"utf-8\">\n",
      "        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <meta name=\"apple-itunes-app\" content=\"app-id=342792525, app-argument=imdb:///?src=mdot\">\n",
      "            <script type=\"text/javascript\">var ue_t0=window.ue_t0||+new Date();</script>\n",
      "            <script type=\"text/javascript\">\n",
      "                var ue_mid = \"A1EVAM02EL8SFB\"; \n",
      "                var\n"
     ]
    }
   ],
   "source": [
    "response = get(url)\n",
    "print(response.text[:500]) #acccessing the .text attribute of response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Understanding the HTML structure of the page\n",
    "\n",
    "As we can see get() method pulls up the html document for the url. To further pull out the data we want we need to closely inspect the HTML content of the page. We can turn to the developer tools of chrome for this, cntrl+shift+i or simply right clicking on the element you want to study and seelcting the inspect element will pull up that data set for you. (This is performed on chrome bust should work with other browsers as well.)\n",
    "\n",
    "We observe that there is a div tag for each movie. Thus, we can simply loop through the 50 dev tags assosicated with each movie using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs # importing BeautifulSoup as bs\n",
    "\n",
    "html_soup = bs(response.text, \"html.parser\") #using python's built in HTML parser\n",
    "type(html_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before extracting 50 div containers, we need to figure out what makes them unique. While exploring the HTML content we find that the class attribute has two values \"lister-item\" and \"mode-advanced\". This combination is unique to all the div containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_containers = html_soup.find_all(\"div\", class_ = \"lister-item mode-advanced\") #find_all() used to find all the tags\n",
    "print(type(movie_containers))\n",
    "len(movie_containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_all() returned a ResultSet object with the length of 50 movies we are interested in.\n",
    "\n",
    "Now, we'll select the conatainers one by one and extract the elements of our interest like:\n",
    "\n",
    "- The name of movie.\n",
    "- The year of release.\n",
    "- The IMDB rating.\n",
    "- The metascore.\n",
    "- The number of votes\n",
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list to store scraped value data in:\n",
    "movie_names = []\n",
    "year_release = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "movie_description = []\n",
    "certificate = []\n",
    "runtime = []\n",
    "genre = []\n",
    "director_name = []\n",
    "star_cast = []\n",
    "gross_value = []\n",
    "\n",
    "#extract data from individual movie container\n",
    "for container in movie_containers:\n",
    "    \n",
    "   \n",
    "    #if movie has Metascore, then extract:\n",
    "    if container.find(\"div\", class_ = \"ratings-metascore\") is not None:\n",
    "        \n",
    "        \n",
    "        #the movie_name\n",
    "        name = container.h3.a.text\n",
    "        movie_names.append(name)\n",
    "        \n",
    "        #the year od release\n",
    "        release = container.find(\"span\", class_ = \"lister-item-year text-muted unbold\").text\n",
    "        year_release.append(release)\n",
    "        \n",
    "        #the ratings for the movies\n",
    "        ratings = float(container.strong.text)\n",
    "        imdb_ratings.append(ratings)\n",
    "        \n",
    "        #the metascores\n",
    "        meta = container.find(\"span\", class_ = \"metascore\").text\n",
    "        metascores.append(int(meta))\n",
    "        \n",
    "        #the votes\n",
    "        vote = container.find(\"span\", attrs = {\"name\":\"nv\"})['data-value']\n",
    "        votes.append(int(vote))\n",
    "        \n",
    "        #the certificate\n",
    "        certi = container.find(\"span\", class_ = \"certificate\").text\n",
    "        certificate.append(certi)\n",
    "        \n",
    "        #the runtime\n",
    "        run = container.find(\"span\", class_ =\"runtime\").text\n",
    "        runtime.append(run)\n",
    "        \n",
    "        #the genre\n",
    "        gen = container.find(\"span\", class_ =\"genre\").text\n",
    "        genre.append(gen)\n",
    "        \n",
    "        #fetching all <p> tags\n",
    "        content = container.find_all(\"p\")\n",
    "        \n",
    "        #the description\n",
    "        desc = content[1].text\n",
    "        movie_description.append(desc)\n",
    "        \n",
    "        #subsetting all the <a> tags in 3rd <p> tag\n",
    "        content_2 = content[2].find_all(\"a\")\n",
    "        \n",
    "        #the director\n",
    "        director = content_2[0].text\n",
    "        director_name.append(director)\n",
    "        \n",
    "        #the gross value\n",
    "        if len(container.find_all(\"span\", attrs = {\"name\":\"nv\"})) >= 2:\n",
    "            gross = container.find_all(\"span\", attrs = {\"name\":\"nv\"})[1]['data-value']\n",
    "            gross_value.append(gross)\n",
    "        else:\n",
    "            gross_value.append(None)\n",
    "        #extracting artists names\n",
    "        temp = []\n",
    "        for i in range(len(content_2)-1):\n",
    "            temp.append(content_2[i].text)\n",
    "        star_cast.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.DataFrame({\"movie_names\":movie_names,\n",
    "                        \"year_release\":year_release,\n",
    "                        \"imdb_ratings\":imdb_ratings,\n",
    "                        \"metscores\":metascores,\n",
    "                        \"votes\":votes,\n",
    "                        \"movie_description\":movie_description,\n",
    "                        \"certificate\":certificate,\n",
    "                        \"runtime\":runtime,\n",
    "                        \"genre\":genre,\n",
    "                        \"director_name\": director_name,\n",
    "                        \"star_cast\": star_cast,\n",
    "                        \"gross_value\":gross_value\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certificate</th>\n",
       "      <th>director_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>gross_value</th>\n",
       "      <th>imdb_ratings</th>\n",
       "      <th>metscores</th>\n",
       "      <th>movie_description</th>\n",
       "      <th>movie_names</th>\n",
       "      <th>runtime</th>\n",
       "      <th>star_cast</th>\n",
       "      <th>votes</th>\n",
       "      <th>year_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>James Mangold</td>\n",
       "      <td>\\nAction, Drama, Sci-Fi</td>\n",
       "      <td>226,277,068</td>\n",
       "      <td>8.1</td>\n",
       "      <td>77</td>\n",
       "      <td>\\nIn the near future, a weary Logan cares for ...</td>\n",
       "      <td>Logan</td>\n",
       "      <td>137 min</td>\n",
       "      <td>[James Mangold, Hugh Jackman, Patrick Stewart,...</td>\n",
       "      <td>450551</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PG-13</td>\n",
       "      <td>Patty Jenkins</td>\n",
       "      <td>\\nAction, Adventure, Fantasy</td>\n",
       "      <td>412,563,408</td>\n",
       "      <td>7.5</td>\n",
       "      <td>76</td>\n",
       "      <td>\\nWhen a pilot crashes and tells of conflict i...</td>\n",
       "      <td>Wonder Woman</td>\n",
       "      <td>141 min</td>\n",
       "      <td>[Patty Jenkins, Gal Gadot, Chris Pine, Robin W...</td>\n",
       "      <td>375343</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PG-13</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>\\nAction, Drama, History</td>\n",
       "      <td>188,373,161</td>\n",
       "      <td>8.1</td>\n",
       "      <td>94</td>\n",
       "      <td>\\nAllied soldiers from Belgium, the British Em...</td>\n",
       "      <td>Dunkirk</td>\n",
       "      <td>106 min</td>\n",
       "      <td>[Christopher Nolan, Fionn Whitehead, Barry Keo...</td>\n",
       "      <td>347160</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PG-13</td>\n",
       "      <td>James Gunn</td>\n",
       "      <td>\\nAction, Adventure, Sci-Fi</td>\n",
       "      <td>389,813,101</td>\n",
       "      <td>7.7</td>\n",
       "      <td>67</td>\n",
       "      <td>\\nThe Guardians must fight to keep their newfo...</td>\n",
       "      <td>Guardians of the Galaxy Vol. 2</td>\n",
       "      <td>136 min</td>\n",
       "      <td>[James Gunn, Chris Pratt, Zoe Saldana, Dave Ba...</td>\n",
       "      <td>341017</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG-13</td>\n",
       "      <td>Rian Johnson</td>\n",
       "      <td>\\nAction, Adventure, Fantasy</td>\n",
       "      <td>617,422,777</td>\n",
       "      <td>7.5</td>\n",
       "      <td>85</td>\n",
       "      <td>\\nRey develops her newly discovered abilities ...</td>\n",
       "      <td>Star Wars: Episode VIII - The Last Jedi</td>\n",
       "      <td>152 min</td>\n",
       "      <td>[Rian Johnson, Daisy Ridley, John Boyega, Mark...</td>\n",
       "      <td>314684</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  certificate      director_name                                     genre  \\\n",
       "0           R      James Mangold       \\nAction, Drama, Sci-Fi               \n",
       "1       PG-13      Patty Jenkins  \\nAction, Adventure, Fantasy               \n",
       "2       PG-13  Christopher Nolan      \\nAction, Drama, History               \n",
       "3       PG-13         James Gunn   \\nAction, Adventure, Sci-Fi               \n",
       "4       PG-13       Rian Johnson  \\nAction, Adventure, Fantasy               \n",
       "\n",
       "   gross_value  imdb_ratings  metscores  \\\n",
       "0  226,277,068           8.1         77   \n",
       "1  412,563,408           7.5         76   \n",
       "2  188,373,161           8.1         94   \n",
       "3  389,813,101           7.7         67   \n",
       "4  617,422,777           7.5         85   \n",
       "\n",
       "                                   movie_description  \\\n",
       "0  \\nIn the near future, a weary Logan cares for ...   \n",
       "1  \\nWhen a pilot crashes and tells of conflict i...   \n",
       "2  \\nAllied soldiers from Belgium, the British Em...   \n",
       "3  \\nThe Guardians must fight to keep their newfo...   \n",
       "4  \\nRey develops her newly discovered abilities ...   \n",
       "\n",
       "                               movie_names  runtime  \\\n",
       "0                                    Logan  137 min   \n",
       "1                             Wonder Woman  141 min   \n",
       "2                                  Dunkirk  106 min   \n",
       "3           Guardians of the Galaxy Vol. 2  136 min   \n",
       "4  Star Wars: Episode VIII - The Last Jedi  152 min   \n",
       "\n",
       "                                           star_cast   votes year_release  \n",
       "0  [James Mangold, Hugh Jackman, Patrick Stewart,...  450551       (2017)  \n",
       "1  [Patty Jenkins, Gal Gadot, Chris Pine, Robin W...  375343       (2017)  \n",
       "2  [Christopher Nolan, Fionn Whitehead, Barry Keo...  347160       (2017)  \n",
       "3  [James Gunn, Chris Pratt, Zoe Saldana, Dave Ba...  341017       (2017)  \n",
       "4  [Rian Johnson, Daisy Ridley, John Boyega, Mark...  314684       (2017)  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything went just as expected!\n",
    "\n",
    "As a side note if you run the code in a country where english is not the main language, it is very likely that you will get the movie names translated into the main language of that country. To avoid such issues, include the headers = {\"Accept-Language\": \"en-US, en;q=0.5\"} as an argument in the get() command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for multiple pages\n",
    "\n",
    "Building a script to scrape multiple pages can be a bit more challenging, we will have to build upon our old script by adding three more things:\n",
    "\n",
    "- Making all the requests we want from within the loop.\n",
    "- Controlling the loops rate to avoid bombarding the server with requests.\n",
    "- Monitoring the loop while it is in progress.\n",
    "\n",
    "We'll scope through the first 4 pages of each year in the range 2000-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing URL parameters\n",
    "\n",
    "As described before, the URl changes certain logic as the web page changes.\n",
    "\n",
    "As we are making requests, we'll only have to vary the values of two parameters of the URL: \"release_date\" and \"page\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [str(i) for i in range(1,6)] #creating list of strings corresponding to 4 pages\n",
    "years = [str(i) for i in range(2000,2019)] #creating list corresponding to years 2000-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling the crawl rate\n",
    "\n",
    "If we avoid flooding the server with tens of request per second, then we are much likely to avoid our Ip being banned permenantly. We also avpid disrupting the activity of the website we scrape by allowing server to respond to other user's requests too.\n",
    "\n",
    "We'll control the loop's rate by using the sleep() function in the python's \"time\" module. This will pause the execution of the loop for a specified amount of seconds.\n",
    "\n",
    "To mimic the human behavious and to render our requests legit we will vary the amount of waiting time between requests by using the randint() function from python's \"random\" module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Monitoring the loop as it's still going\n",
    "\n",
    "Given that we have so many pages to scan through, it's better to have a way to moniter them while we are looping through them. This process in completely optional but is very helpful while debugging the process.If you are looping through say a 100+ pages, I'd say this is a must have feature.\n",
    "\n",
    "For our script, we'll make sure to use this feature and measure the following parameters:\n",
    "\n",
    "- The frequency of requests, just to make sure we are not overloading the server.\n",
    "\n",
    "- The number of requests, so we can halt the loop incase the number of requests is exceeded.\n",
    "\n",
    "- The status code of our requests, so we make sure the server is sending back the correct responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 95, Frequency: 0.06793686965402597 requests/s\n",
      "5 2018\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import clear_output\n",
    "from time import time\n",
    "\n",
    "#redeclaring the variables\n",
    "\n",
    "movie_names = []\n",
    "year_release = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "movie_description = []\n",
    "certificate = []\n",
    "runtime = []\n",
    "genre = []\n",
    "director_name = []\n",
    "star_cast = []\n",
    "gross_value = []\n",
    "\n",
    "#preparing the moniter of the loop\n",
    "start_time = time()\n",
    "requests = 0\n",
    "\n",
    "#for every year in the interval 2000-2018\n",
    "for year in years:\n",
    "    \n",
    "    #for every page in the onterval 1-4\n",
    "    for page in pages:\n",
    "        \n",
    "        #make a get request\n",
    "        response = get(\"http://www.imdb.com/search/title?release_date=\" + year + \"&sort=num_votes,desc&page=\" + page)\n",
    "        \n",
    "        #pause the loop\n",
    "        sleep(randint(8,15))\n",
    "        \n",
    "        #monitor the requests\n",
    "        requests += 1\n",
    "        sleep(randint(1,3))\n",
    "        elapsed_time = time() - start_time\n",
    "        print(\"Request: {}, Frequency: {} requests/s\".format(requests, requests/elapsed_time))\n",
    "        print(page, year)\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        #throw a warning for non-200 status codes\n",
    "        if response.status_code != 200:\n",
    "            warn(\"Request: {}, Status Code: {} \".format(requests, response.status_code))\n",
    "            \n",
    "            \n",
    "        #break the loop if the frequency of request is too higih\n",
    "        if requests > 101:\n",
    "            warn(\"Number of requests was greater than expected.\")\n",
    "            break\n",
    "            \n",
    "        #parse the content through the html.parser using BeautifulSoup\n",
    "        html_page = bs(response.text, \"html.parser\")\n",
    "        \n",
    "        #select all 50 movie container for a single page\n",
    "        containers = html_page.find_all(\"div\", class_ = \"lister-item mode-advanced\")\n",
    "        \n",
    "        #for every movie of the 50 movies\n",
    "        for container in containers:\n",
    "            \n",
    "            #if movie has Metascore, then extract:\n",
    "            if container.find(\"div\", class_ = \"ratings-metascore\") is not None:\n",
    "                \n",
    "                #the movie_name\n",
    "                name = container.h3.a.text\n",
    "                movie_names.append(name)\n",
    "\n",
    "                #the year od release\n",
    "                release = container.find(\"span\", class_ = \"lister-item-year text-muted unbold\").text\n",
    "                year_release.append(release)\n",
    "\n",
    "                #the ratings for the movies\n",
    "                ratings = float(container.strong.text)\n",
    "                imdb_ratings.append(ratings)\n",
    "\n",
    "                #the metascores\n",
    "                meta = container.find(\"span\", class_ = \"metascore\").text\n",
    "                metascores.append(int(meta))\n",
    "\n",
    "                #the votes\n",
    "                vote = container.find(\"span\", attrs = {\"name\":\"nv\"})['data-value']\n",
    "                votes.append(int(vote))\n",
    "\n",
    "                #the certificate\n",
    "                if container.find(\"span\", class_ = \"certificate\") is not None:\n",
    "                    certi = container.find(\"span\", class_ = \"certificate\").text\n",
    "                    certificate.append(certi)\n",
    "                else:\n",
    "                    certificate.append(None)\n",
    "\n",
    "                #the runtime\n",
    "                if container.find(\"span\", class_ =\"runtime\") is not None:\n",
    "                    run = container.find(\"span\", class_ =\"runtime\").text\n",
    "                    runtime.append(run)\n",
    "                else:\n",
    "                    runtime.append(None)\n",
    "\n",
    "                #the genre\n",
    "                if container.find(\"span\", class_ =\"genre\") is not None:\n",
    "                    gen = container.find(\"span\", class_ =\"genre\").text\n",
    "                    genre.append(gen)\n",
    "                else:\n",
    "                    genre.append(None)\n",
    "\n",
    "                #fetching all <p> tags\n",
    "                content = container.find_all(\"p\")\n",
    "\n",
    "                #the description\n",
    "                if content[1] is not None:\n",
    "                    desc = content[1].text\n",
    "                    movie_description.append(desc)\n",
    "                else:\n",
    "                    movie_description.append(None)\n",
    "\n",
    "                #subsetting all the <a> tags in 3rd <p> tag\n",
    "                content_2 = content[2].find_all(\"a\")\n",
    "\n",
    "                #the director\n",
    "                if content_2[0] is not None:\n",
    "                    director = content_2[0].text\n",
    "                    director_name.append(director)\n",
    "                else:\n",
    "                    director_name.append(None)\n",
    "\n",
    "                #the gross value\n",
    "                if len(container.find_all(\"span\", attrs = {\"name\":\"nv\"})) >= 2:\n",
    "                    gross = container.find_all(\"span\", attrs = {\"name\":\"nv\"})[1]['data-value']\n",
    "                    gross_value.append(gross)\n",
    "                else:\n",
    "                    gross_value.append(None)\n",
    "                    \n",
    "                #extracting artists names\n",
    "                if content_2[1] is not None:\n",
    "                    temp = []\n",
    "                    for i in range(len(content_2)-1):\n",
    "                        temp.append(content_2[i].text)\n",
    "                    star_cast.append(temp)\n",
    "                else:    \n",
    "                    star_cast.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing scraped data into a data frame.\n",
    "\n",
    "imdb_movie_dataset = pd.DataFrame({\"movie_names\":movie_names,\n",
    "                        \"year_release\":year_release,\n",
    "                        \"imdb_ratings\":imdb_ratings,\n",
    "                        \"metscores\":metascores,\n",
    "                        \"votes\":votes,\n",
    "                        \"movie_description\":movie_description,\n",
    "                        \"certificate\":certificate,\n",
    "                        \"runtime\":runtime,\n",
    "                        \"genre\":genre,\n",
    "                        \"director_name\": director_name,\n",
    "                        \"star_cast\": star_cast,\n",
    "                        \"gross_value\":gross_value\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movie_dataset.to_csv(\"imdb_movie_dataset.csv\") #stores the DataFrame as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have succesfully scraped the IMDB website, now let's clean the dataset soo it can be stored in a database and further used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\amar\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "imdb_movie_dataset = pd.read_csv(\"imdb_movie_dataset.csv\") #reading the file we previously created.\n",
    "import re\n",
    "\n",
    "#the below code is used to clean the scraped data into a storable and further usable format. \n",
    "#We have used regular expressions in order to do so\n",
    "\n",
    "for i in range(len(imdb_movie_dataset['star_cast'])):\n",
    "    \n",
    "    #cleaning star_cast column\n",
    "    imdb_movie_dataset['star_cast'][i] = re.findall(r\"'([^']*)'\",imdb_movie_dataset['star_cast'][i])\n",
    "    \n",
    "    #cleaning genre column\n",
    "    imdb_movie_dataset['genre'][i] = re.findall(\"([^\\\\r\\\\n\\s,][a-zA-Z]+)\", imdb_movie_dataset['genre'][i])\n",
    "    \n",
    "    #cleaning gross_value\n",
    "    if (type(imdb_movie_dataset[\"gross_value\"][i]) == float) is not True:\n",
    "        imdb_movie_dataset['gross_value'][i] = int(imdb_movie_dataset['gross_value'][i].replace(\",\",\"\"))\n",
    "    else:\n",
    "        imdb_movie_dataset['gross_value'][i] = None\n",
    "    #cleaning movie_description\n",
    "    imdb_movie_dataset['movie_description'][i] = str(re.findall(r\"[^\\\\r\\n].+\",imdb_movie_dataset['movie_description'][i])[0])\n",
    "    \n",
    "    #cleaning movie_names\n",
    "    imdb_movie_dataset[\"movie_names\"][i] = str(imdb_movie_dataset[\"movie_names\"][i][0])\n",
    "    \n",
    "    #cleaning runtime\n",
    "    if (type(imdb_movie_dataset[\"runtime\"][i])== float) is not True:\n",
    "        imdb_movie_dataset[\"runtime\"][i] = int(re.findall(r\"[0-9].+[^a-zA-Z-]\",imdb_movie_dataset['runtime'][i])[0])\n",
    "    else:\n",
    "        imdb_movie_dataset[\"runtime\"][i] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3475, 13)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movie_dataset.shape # checking the shape of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_movie_dataset.to_csv(\"imdb_movie_dataset.csv\") #stores the DataFrame as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!\n",
    "\n",
    "We have successfuly completed the scraping and cleaning of the data. In the next workbook we shall use this dataset to store it in a PostgreSQL database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
